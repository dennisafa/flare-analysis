{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "Found 1 File(s)\n",
      "INFO: Found cached file ./mastDownload/K2/ktwo201885041-c14_lc/ktwo201885041-c14_lpd-targ.fits.gz with expected size 8768094. [astroquery.query]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/signal/_savitzky_golay.py:135: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  coeffs, _, _, _ = lstsq(A, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flares subtracted!\n",
      "Flares subtracted!\n",
      "Flares subtracted!\n",
      "Flares subtracted!\n",
      "Flares subtracted!\n",
      "Flares subtracted!\n",
      "Flares subtracted!\n",
      "Flares subtracted!\n",
      "Flares subtracted!\n",
      "Flares subtracted!\n",
      "Flares subtracted!\n",
      "Flares subtracted!\n",
      "Flares subtracted!\n",
      "3694\n",
      "Bounds [(None, None), (None, None), (None, None)]\n",
      "0.0\n",
      "Initial log likelihood 79.9333022181\n",
      "initial parameter vector [ 0.3678334   1.09861229 -0.69314718]\n",
      "Final log likelihood 194.062896744\n",
      "final parameter vector [-0.06088393  2.282029    5.35209724]\n",
      "      fun: -194.06289674432475\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  3.52532275e-05,  -3.19542925e-03,   2.00326109e-04])\n",
      "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 22\n",
      "      nit: 17\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-0.06088393,  2.282029  ,  5.35209724])\n",
      "Running burn-in\n",
      "Running production chain\n"
     ]
    }
   ],
   "source": [
    "import george\n",
    "from george import kernels\n",
    "import numpy as np\n",
    "from lightkurve import KeplerTargetPixelFile\n",
    "import matplotlib.pyplot as pl\n",
    "import aflare as ap\n",
    "import flaredetect as fd\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from scipy.signal import savgol_filter as sf\n",
    "from scipy.optimize import minimize\n",
    "from numpy import asarray\n",
    "import emcee\n",
    "\n",
    "class Flare:\n",
    "    flux = []\n",
    "    time = []\n",
    "\n",
    "    def __init__(self, flare, r1, r2):\n",
    "\n",
    "        flare = flare.remove_nans().remove_outliers()\n",
    "        self.flux = flare.flux[r1:r2]\n",
    "        self.flux = self.flux[np.logical_not(np.isnan(self.flux))]\n",
    "        self.flux = (self.flux - min(self.flux)) / (max(self.flux) - min(self.flux))\n",
    "        self.time = flare.time[:len(self.flux)]\n",
    "\n",
    "\n",
    "    def guesspeaks(self): # gathers the peaks in the set of data, then returns a list of flare times, peaks, and fwhm\n",
    "        self.detflares = fd.flaredetectpeak(self.flux)\n",
    "        self.flarecount = fd.getlength()\n",
    "        self.nflares = np.shape(self.detflares)[0]\n",
    "        self.params = np.zeros([self.nflares, 3])\n",
    "        for i, flareVal in enumerate(self.detflares):\n",
    "            self.flarepeak = flareVal\n",
    "            self.flaretime = self.findfluxtime(self.flarepeak, self.flux, self.time)\n",
    "            p = [self.flaretime, 0.002, self.flarepeak]\n",
    "            self.params[i, :] = p\n",
    "        return np.log(self.params)\n",
    "\n",
    "\n",
    "    def findfluxtime(self, flarepeak, flux, time):  # retrieves the time of the flare\n",
    "        tof = time\n",
    "        for i, flare in enumerate(flux):\n",
    "            if flare == flarepeak:\n",
    "                return tof[i]\n",
    "\n",
    "\n",
    "    def getmodel(self, p, data): # computes the model of the flares using appaloosa's aflare1 function\n",
    "        time, y, nflares = data\n",
    "        p = np.exp(p)\n",
    "        model = np.zeros_like([time])\n",
    "        p = np.reshape(p, (nflares, 3))\n",
    "        for i in range(nflares):\n",
    "            model += ap.aflare1(time, tpeak=p[i, 0], fwhm=p[i, 1], ampl=p[i, 2], upsample=False, uptime=10)\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "def lnprob(p):\n",
    "    # Trivial uniform prior.\n",
    "    if np.any((-100 > p[1:]) + (p[1:] > 100)):\n",
    "        return -np.inf\n",
    "\n",
    "    # Update the kernel and compute the lnlikelihood.\n",
    "    gp.set_parameter_vector(p)\n",
    "    return gp.log_likelihood(y, quiet=True)\n",
    "\n",
    "\n",
    "'''George modeling'''\n",
    "def computegeorge (flux, time):\n",
    "    global gp\n",
    "    global y\n",
    "\n",
    "    y = flux\n",
    "    x = time\n",
    "\n",
    "    kernel = kernels.CosineKernel(log_period=np.log(3), axes=0) + kernels.ExpSquaredKernel(metric=0.5)\n",
    "    gp = george.GP(kernel, mean=np.mean(y), fit_mean=True)\n",
    "    gp.compute(x, y)\n",
    "    print('Bounds', gp.get_parameter_bounds())\n",
    "    print(gp.log_prior())\n",
    "    print('Initial log likelihood', gp.log_likelihood(y))\n",
    "    print('initial parameter vector', gp.get_parameter_vector())\n",
    "    res = minimize(neg_ln_like, gp.get_parameter_vector(), jac=grad_neg_ln_like, method=\"L-BFGS-B\")\n",
    "    gp.set_parameter_vector(res.x)\n",
    "    print('Final log likelihood', gp.log_likelihood(y))\n",
    "    print('final parameter vector', res.x)\n",
    "    print(res)\n",
    "\n",
    "    '''Emcee sampling'''\n",
    "    nwalkers, ndim = 36, len(gp)\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob)\n",
    "\n",
    "    # Initialize the walkers.\n",
    "    p0 = gp.get_parameter_vector() + 1e-4 * np.random.randn(nwalkers, ndim)\n",
    "\n",
    "    print(\"Running burn-in\")\n",
    "    p0, _, _ = sampler.run_mcmc(p0, 200)\n",
    "\n",
    "    print(\"Running production chain\")\n",
    "    sampler.run_mcmc(p0, 200)\n",
    "    return sampler\n",
    "\n",
    "\n",
    "\n",
    "    '''End emcee'''\n",
    "\n",
    "   \n",
    "\n",
    "def neg_ln_like(p):\n",
    "    gp.set_parameter_vector(p)\n",
    "    return -gp.log_likelihood(y)\n",
    "\n",
    "def grad_neg_ln_like(p):\n",
    "    gp.set_parameter_vector(p)\n",
    "    return -gp.grad_log_likelihood(y)\n",
    "\n",
    "\n",
    "def setbounds(flux):\n",
    "    flux = asarray(flux).ravel()\n",
    "    bounds = np.zeros([len(flux),2])\n",
    "    for i in range(len(flux)):\n",
    "        for j in range(2):\n",
    "            if j < 1:\n",
    "                bounds[i][j] = flux[i]\n",
    "            else:\n",
    "                bounds[i][j] = flux[i] ** 1/20\n",
    "    return bounds\n",
    "\n",
    "'''End George Modeling'''\n",
    "\n",
    "def remove_flares(flare):\n",
    "\n",
    "\n",
    "    while len(fd.flaredetectpeak(flare.flux)) > 0:# while flares are still being detected, compute its model and subtract flares\n",
    "        tempmodel = sub_flare_model(flare)\n",
    "        flare.flux = flare.flux-tempmodel.flatten()\n",
    "\n",
    "        print(\"Flares subtracted!\")\n",
    "\n",
    "\n",
    "    return flare\n",
    "\n",
    "\n",
    "def sub_flare_model(flare):\n",
    "    guessparams = flare.guesspeaks()\n",
    "    model = flare.getmodel(guessparams, [flare.time, flare.flux,\n",
    "                                         flare.nflares])\n",
    "    return model\n",
    "\n",
    "\n",
    "def flatten(flare):\n",
    "        # 113,008 points\n",
    "\n",
    "        sf_model = sf(flare.flux, 501, 3)\n",
    "        rotation = sf(sf_model, 501, 3)\n",
    "        for i in range(10):\n",
    "            rotation = sf(rotation, 501, 3)\n",
    "        flat_flux = flare.flux - rotation\n",
    "        flare.flux = flat_flux\n",
    "\n",
    "        # smo = pd.rolling_median(flare.flux, 100, center=True)\n",
    "        # smo2 = pd.rolling_median(flare.flux - smo, 2, center=True)\n",
    "\n",
    "\n",
    "        pl.plot(flare.time, flare.flux)\n",
    "        pl.show()\n",
    "        remove_flares(flare)\n",
    "        flare.flux += rotation\n",
    "\n",
    "\n",
    "\n",
    "        return flare\n",
    "\n",
    "def running_sum(list, window):\n",
    "    j = 0\n",
    "    new = 0\n",
    "    new_list = []\n",
    "    for i in range(len(list)):\n",
    "        if j > window:\n",
    "            new_list.append(new)\n",
    "            new = 0\n",
    "            j = 0\n",
    "        else:\n",
    "            new+=list[i]\n",
    "            j+=1\n",
    "\n",
    "    return new_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fits_file = fits.open('/Users/Dennis/Desktop/newwolfdata/files/ktwo201885041_01_kasoc-ts_slc_v1.fits')\n",
    "# flux = fits_file[1].data['flux']\n",
    "# time = fits_file[1].data['time']\n",
    "# flux = flux[np.logical_not(np.isnan(flux))]\n",
    "# flux = (flux/ np.median(flux)) - 1\n",
    "# flux = (flux-min(flux))/(max(flux)-min(flux))\n",
    "#\n",
    "# flux = running_sum(flux, 30)\n",
    "# flux = np.array(flux)\n",
    "# flux = pd.rolling_median(flux, 100, center=True)\n",
    "# flux = flux[np.logical_not(np.isnan(flux))]\n",
    "# flux = (flux/ np.median(flux)) - 1\n",
    "# time = time[:len(flux)]\n",
    "# g = computegeorge(flux, time)\n",
    "# pl.plot(time, flux)\n",
    "# pl.plot(time, g)\n",
    "# pl.show()\n",
    "\n",
    "# w = 30\n",
    "# flux = running_sum(flux, w)\n",
    "# time = time[:len(flux)]\n",
    "\n",
    "print(\"Creating model...\")\n",
    "\n",
    "wolf = KeplerTargetPixelFile.from_archive('201885041')\n",
    "lc359 = wolf.to_lightcurve(aperture_mask=wolf.pipeline_mask)\n",
    "\n",
    "\n",
    "#flare = Flare(lc359, 0, len(lc359.flux))\n",
    "flare = Flare(lc359, 0, len(lc359.flux))\n",
    "\n",
    "sav_gol_model = sf(flare.flux, 101, 3)\n",
    "flare.flux -= sav_gol_model\n",
    "flare = remove_flares(flare)\n",
    "flare.flux += sav_gol_model\n",
    "\n",
    "\n",
    "print(len(lc359.flux))\n",
    "g = computegeorge(flare.flux, flare.time) # now compute the GP with flares removed\n",
    "\n",
    "# flare = flatten(flare)\n",
    "# flare.flux = pd.rolling_median(flare.flux, 100, center=True)\n",
    "# flare.flux = flare.flux[np.logical_not(np.isnan(flare.flux))]\n",
    "# flare.time = flare.time[:len(flare.flux)]\n",
    "#\n",
    "# g = computegeorge(flare.flux, flare.time)\n",
    "# pl.plot(g)\n",
    "# pl.show()\n",
    "\n",
    "\n",
    "\n",
    "# flare.flux = remove_flares(flare)\n",
    "#\n",
    "# pl.plot(flare.time, flare.flux)\n",
    "# pl.show()\n",
    "# pl.clf()\n",
    "#\n",
    "# flare.flux += clean_model\n",
    "#\n",
    "# pl.plot(flare.time, flare.flux)\n",
    "# pl.show()\n",
    "# pl.clf()\n",
    "# george_model = computegeorge(flare.flux, flare.time)\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
